{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8973aa7-0553-4d25-b744-2ecfc028868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ctypes import *\n",
    "from typing import List\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import xir\n",
    "import vart\n",
    "import vitis_ai_library\n",
    "import os\n",
    "import math\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from unet.dataset import ImageToImage2D, JointTransform2D\n",
    "from unet.metrics import jaccard_index, f1_score, LogNLLLoss\n",
    "from unet.utils import MetricList, Logger\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f49542-e8bf-4a98-899d-cda34e4867d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./images_folder\"\n",
    "results_path = \"./build_test/comp_model/\"\n",
    "model_path = \"./build_test/comp_model/UNet2D_compiled.xmodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be18950d-aa5c-421a-a35a-3c505ca82a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, dataset, n_batch=1, metric_list=MetricList({}), loss_function=LogNLLLoss()):\n",
    "    \"\"\"\n",
    "    Validation of given dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: an instance of unet.dataset.ImageToImage2D\n",
    "        n_batch: size of batch during training\n",
    "            metric_list: unet.utils.MetricList object, which contains metrics\n",
    "            to be recorded during validation\n",
    "\n",
    "    Returns:\n",
    "        logs: dictionary object containing the validation loss and\n",
    "            the metrics given by the metric_list object\n",
    "    \"\"\"\n",
    "\n",
    "    metric_list.reset()\n",
    "    running_val_loss = 0.0\n",
    "        \n",
    "    g = xir.Graph.deserialize(model)\n",
    "    runner = vitis_ai_library.GraphRunner.create_graph_runner(g)\n",
    "    # get a list of runner inputs\n",
    "    inputTensors = runner.get_input_tensors()\n",
    "    output_tensor_buffers = runner.get_outputs()    \n",
    "     \n",
    "    for batch_idx, (X_batch, y_batch, *rest) in enumerate(DataLoader(dataset, batch_size=1)):\n",
    "            \n",
    "        input_image = np.asarray(X_batch, dtype=np.float32) / 255\n",
    "            \n",
    "        inputData = []\n",
    "        for inputTensor in inputTensors:\n",
    "            inputData.append(input_image.reshape(inputTensor.dims))\n",
    "        job_id = runner.execute_async(inputData, output_tensor_buffers)\n",
    "        runner.wait(job_id)\n",
    "            \n",
    "        output = np.array(output_tensor_buffers[0], np.uint8)\n",
    "        mask = np.transpose(output, (0, 3, 1, 2)).astype(np.float32)\n",
    "        y_out = torch.from_numpy(mask)\n",
    "        training_loss = loss_function(y_out, y_batch)\n",
    "        running_val_loss += training_loss.item()\n",
    "        metric_list(y_out, y_batch)\n",
    "\n",
    "    del X_batch, y_batch\n",
    "\n",
    "    logs = {'val_loss': running_val_loss/(batch_idx + 1),\n",
    "                **metric_list.get_results(normalize=batch_idx+1)}\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cc68645-2487-4276-98d8-b68c074aca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_val = JointTransform2D(crop=(256, 256), p_flip=0.5, color_jitter_params=None, long_mask=True)\n",
    "predict_dataset = ImageToImage2D(dataset_dir, tf_val)\n",
    "\n",
    "logger = Logger(verbose=True)\n",
    "metric_list = MetricList({'jaccard': partial(jaccard_index),\n",
    "                                  'f1': partial(f1_score)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c1c466d-92dd-4b3a-9082-7e96208075ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 1.7047607799074542, 'jaccard': 0.019970975973323656, 'f1': 0.4682012813304787}\n"
     ]
    }
   ],
   "source": [
    "logs = val_epoch(model=model_path, dataset=predict_dataset, metric_list=metric_list)\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc0767-6bea-43e5-bdd3-ae7ea1e43428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
